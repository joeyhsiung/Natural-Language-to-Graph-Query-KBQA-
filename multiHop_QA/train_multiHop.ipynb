{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from multiHop_QA.configures import Config_path,Config_output_path,Hyparams_transformers\n",
    "from multiHop_QA.model import Encoder,Decoder,Seq2Seq\n",
    "\n",
    "config = Config_path()\n",
    "config_output = Config_output_path()\n",
    "\n",
    "# USE_CUDA = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QsFHGbNidxDl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RelVocabs():\n",
    "    def __init__(self,train_combination,test_combination):\n",
    "        self.train = train_combination\n",
    "        self.test = test_combination\n",
    "\n",
    "    def __load_relation(self):\n",
    "        relation_train = pd.read_csv(self.train)\n",
    "        relation_test = pd.read_csv(self.test)\n",
    "        rel2id = {}\n",
    "        id2rel = {}\n",
    "        special_char = np.array(['PAD', 'BOS', 'EOS', 'UNK'])\n",
    "        relations = pd.concat([pd.Series(special_char), relation_train['relationship'],\n",
    "                               relation_test['relationship']],\n",
    "                              axis=0)\n",
    "        relations = relations.unique()\n",
    "        idx = 0\n",
    "        for relation in relations:\n",
    "            rel2id[relation] = idx\n",
    "            id2rel[idx] = relation\n",
    "            idx += 1\n",
    "        return rel2id, id2rel\n",
    "\n",
    "    def get_rl_vocabs(self):\n",
    "        return self.__load_relation()\n",
    "\n",
    "\n",
    "class QuesVocabs():\n",
    "    def __init__(self,train_combination,test_combination):\n",
    "        self.train = train_combination\n",
    "        self.test = test_combination\n",
    "\n",
    "    def __load_mask_q(self):\n",
    "        mask_q_train = pd.read_csv(self.train)\n",
    "        mask_q_test = pd.read_csv(self.test)\n",
    "        q2id = {}\n",
    "        id2q = {}\n",
    "        special_char = np.array(['PAD', 'BOS', 'EOS', 'UNK'])\n",
    "        mask_qs = pd.concat([pd.Series(special_char), mask_q_train['q_space'],\n",
    "                             mask_q_test['q_space']],\n",
    "                            axis=0)\n",
    "        mask_qs = mask_qs.str.split(expand=True).stack()\n",
    "        mask_qs = mask_qs.unique()\n",
    "        idx = 0\n",
    "        for mask_q in mask_qs:\n",
    "            q2id[mask_q] = idx\n",
    "            id2q[idx] = mask_q\n",
    "            idx += 1\n",
    "        return q2id, id2q\n",
    "\n",
    "    def get_ques_vocabs(self):\n",
    "        return self.__load_mask_q()\n",
    "\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self,train_combination,test_combination,q2id,rel2id):\n",
    "        self.train = train_combination\n",
    "        self.test = test_combination\n",
    "        self.q2i = q2id\n",
    "        self.rel2id = rel2id\n",
    "\n",
    "    def __split_data(self):\n",
    "        train = pd.read_csv(self.train)\n",
    "        test = pd.read_csv(self.test)\n",
    "        split = test.shape[0] // 2\n",
    "        train_q = self.read_docs_to_seqs(train['q_space'].values, self.q2i)\n",
    "        train_rel = self.read_docs_to_seqs(train['relationship'].values, self.rel2id,is_rel = True)\n",
    "        val_q = self.read_docs_to_seqs(test['q_space'][0:split].values, self.q2i)\n",
    "        val_rel = self.read_docs_to_seqs(test['relationship'][0:split].values, self.rel2id,is_rel = True)\n",
    "        test_q = self.read_docs_to_seqs(test['q_space'][split:-1].values, self.q2i)\n",
    "        test_rel = self.read_docs_to_seqs(test['relationship'][split:-1].values, self.rel2id,is_rel = True)\n",
    "        return train_q, train_rel, val_q, val_rel, test_q, test_rel\n",
    "\n",
    "    def read_docs_to_seqs(self, docs, w2id,is_rel = False):\n",
    "        seqs = []\n",
    "        for doc in docs:\n",
    "            if doc == \"\":\n",
    "                continue\n",
    "            words = doc.split(\" \")\n",
    "            # if is_rel:\n",
    "            #     seq = [w2id[\"BOS\"]]\n",
    "            # else:\n",
    "            #     seq = []\n",
    "            seq = [w2id[\"BOS\"]]\n",
    "            for word in words:\n",
    "                if word in w2id:\n",
    "                    seq.append(w2id[word])\n",
    "            # seq = [w2id[word] for word in words if word in w2id]\n",
    "            seq.append(w2id[\"EOS\"])\n",
    "            seqs.append(seq)\n",
    "        return seqs\n",
    "\n",
    "    def get_mask_data(self):\n",
    "        return self.__split_data()\n",
    "\n",
    "\n",
    "def get_batch(pairs, batch_size):\n",
    "    if batch_size is not None:\n",
    "        rand_list = [random.randint(0, len(pairs) - 1) for i in range(batch_size)]\n",
    "        pairs_batch = [pairs[rand] for rand in rand_list]\n",
    "    else:\n",
    "        pairs_batch = pairs\n",
    "    # pairs_batch = sorted(pairs_batch, key=lambda p:len(p[0]), reverse=True) # sort based on input len, to use pack function of pytorch\n",
    "\n",
    "    qu_batch = [pair[0] for pair in pairs_batch]\n",
    "    rl_batch = [pair[1] for pair in pairs_batch]\n",
    "    qu_lengths = [len(seq) for seq in qu_batch]\n",
    "    rl_lengths = [len(seq) for seq in rl_batch]\n",
    "    max_q_length = max(qu_lengths)\n",
    "    max_r_length = max(rl_lengths)\n",
    "\n",
    "    seqs_padded = []\n",
    "    for seq in qu_batch:\n",
    "        seqs_padded.append(seq + [q2id[\"PAD\"] for pad_num in range(max_q_length - len(seq))])\n",
    "    qu_batch = seqs_padded\n",
    "    seqs_padded = []\n",
    "    for seq in rl_batch:\n",
    "        seqs_padded.append(seq + [rel2id[\"PAD\"] for pad_num in range(max_r_length - len(seq))])\n",
    "    rl_batch = seqs_padded\n",
    "    qu_batch = Variable(torch.LongTensor(qu_batch)) #.transpose(0, 1)\n",
    "    # (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    rl_batch = Variable(torch.LongTensor(rl_batch)) #.transpose(0, 1)\n",
    "    qu_batch = qu_batch.to(device)\n",
    "    rl_batch = rl_batch.to(device)\n",
    "    return qu_batch, qu_lengths, rl_batch, rl_lengths\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "\n",
    "def train(model, train_pairs, optimizer, criterion, clip): #####\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    # for i, batch in enumerate(iterator):\n",
    "    #     src = batch.src\n",
    "    #     trg = batch.trg\n",
    "    src, q_lengths, trg, r_lengths = get_batch(train_pairs, hper_params.BATCH_SIZE)\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(src, trg[:, :-1])\n",
    "    # output = [batch size, trg len - 1, output dim]\n",
    "    # trg = [batch size, trg len]\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output.contiguous().view(-1, output_dim)\n",
    "    trg = trg[:, 1:].contiguous().view(-1)\n",
    "    # output = [batch size * trg len - 1, output dim]\n",
    "    # trg = [batch size * trg len - 1]\n",
    "    loss = criterion(output, trg)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    epoch_loss += loss.item()\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, val_pairs, criterion): #####\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        # for i, batch in enumerate(iterator):\n",
    "        #     src = batch.src\n",
    "        #     trg = batch.trg\n",
    "            src, q_lengths, trg, r_lengths = get_batch(train_pairs, hper_params.BATCH_SIZE)\n",
    "            output, _ = model(src, trg[:, :-1])\n",
    "            # output = [batch size, trg len - 1, output dim]\n",
    "            # trg = [batch size, trg len]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "            # output = [batch size * trg len - 1, output dim]\n",
    "            # trg = [batch size * trg len - 1]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time): #####\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yD_Kyhg6dxDs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,040,245 trainable parameters\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'G:\\\\My Drive\\\\RR-project\\\\NL2GraphQuery-workplace\\\\code\\\\NLtoGQ\\\\models\\\\0727_transformers_best-model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-a6166ffc1b93>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;31m# torch.save(model.state_dict(),\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[1;31m#            os.path.join(config_output.transformers_path,model_name))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         torch.save(model,\n\u001B[0m\u001B[0;32m     74\u001B[0m                    os.path.join(config_output.transformers_path, model_name))\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NL2GraphQuery\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    374\u001B[0m     \u001B[0m_check_dill_version\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpickle_module\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    375\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 376\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_use_new_zipfile_serialization\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NL2GraphQuery\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    231\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;34m'w'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NL2GraphQuery\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'G:\\\\My Drive\\\\RR-project\\\\NL2GraphQuery-workplace\\\\code\\\\NLtoGQ\\\\models\\\\0727_transformers_best-model.pt'"
     ]
    }
   ],
   "source": [
    "train_combination = config.train_combination_path\n",
    "test_combination = config.test_combination_path\n",
    "\n",
    "m_q_vocabs = QuesVocabs(train_combination,test_combination)\n",
    "q2id, id2q = m_q_vocabs.get_ques_vocabs()\n",
    "\n",
    "rel_vocabs = RelVocabs(train_combination,test_combination)\n",
    "rel2id, id2rel = rel_vocabs.get_rl_vocabs()\n",
    "\n",
    "loadData = LoadData(train_combination,test_combination,q2id,rel2id)\n",
    "train_q, train_r, val_q, val_r, test_q, test_r = loadData.get_mask_data()\n",
    "\n",
    "train_pairs = [(s_seq, t_seq) for s_seq, t_seq in zip(train_q, train_r)]\n",
    "val_pairs = [(s_seq, t_seq) for s_seq, t_seq in zip(val_q, val_r)]\n",
    "test_pairs = [(s_seq, t_seq) for s_seq, t_seq in zip(test_q, test_r)]\n",
    "\n",
    "#################################################################################\n",
    "# Initialize hyper-parameters\n",
    "hper_params = Hyparams_transformers()\n",
    "model_name = \"0727_transformers_best-model.pt\"\n",
    "INPUT_DIM = len(q2id) ##\n",
    "OUTPUT_DIM = len(rel2id) ##\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "q_batch, q_lengths, r_batch, r_lengths = get_batch(train_pairs, hper_params.BATCH_SIZE)\n",
    "\n",
    "# Initialize Model\n",
    "enc = Encoder(INPUT_DIM,\n",
    "              hper_params.HID_DIM,\n",
    "              hper_params.ENC_LAYERS,\n",
    "              hper_params.ENC_HEADS,\n",
    "              hper_params.ENC_PF_DIM,\n",
    "              hper_params.ENC_DROPOUT,\n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM,\n",
    "              hper_params.HID_DIM,\n",
    "              hper_params.DEC_LAYERS,\n",
    "              hper_params.DEC_HEADS,\n",
    "              hper_params.DEC_PF_DIM,\n",
    "              hper_params.DEC_DROPOUT,\n",
    "              device)\n",
    "\n",
    "SRC_PAD_IDX = q2id['PAD']\n",
    "TRG_PAD_IDX = rel2id['PAD']\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)  # input/target pad index\n",
    "# show model's parameters quantity\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "# Initialize model's weights\n",
    "model.apply(initialize_weights)\n",
    "# apply learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hper_params.LEARNING_RATE)\n",
    "# use loss entropy for backpropagation\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(hper_params.N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_pairs, optimizer, criterion, hper_params.CLIP)\n",
    "    valid_loss = evaluate(model, val_pairs, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        # torch.save(model.state_dict(),\n",
    "        #            os.path.join(config_output.transformers_path,model_name))\n",
    "        torch.save(model,\n",
    "                   os.path.join(config_output.transformers_path, model_name))\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "# # print test score\n",
    "# # model.load_state_dict(\n",
    "# #     torch.load(os.path.join(config_output.transformers_path,model_name)))\n",
    "# model_ = torch.load(os.path.join(config_output.transformers_path, '0727_transformers_best-model.pt'))\n",
    "# test_loss = evaluate(model_, test_pairs, criterion)\n",
    "# print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bAm1rUEMdxD2",
    "outputId": "9af8e688-a171-4401-b900-a317707a6ada"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "S1yGMKO9dxD6"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "train_multiHop.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}